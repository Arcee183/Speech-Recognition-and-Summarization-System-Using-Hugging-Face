{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9dc067-e18c-423c-8813-76610a4ecef8",
   "metadata": {},
   "source": [
    "# Build a Speech Recognition and Summarization System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465cf03d-b9f2-4f42-b75c-93d42db56333",
   "metadata": {},
   "source": [
    "In this project, we are going to use a system that recognizes speech such as python's vosk library and connect it to a summarization system. This will allow us to transcribe audio files and produce somewhat accuracy summaries of audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4f809-a6cd-4c3d-90e0-480431894227",
   "metadata": {},
   "source": [
    "In order to complete this project you will need the following libraries:\n",
    "- vosk\n",
    "- pydub\n",
    "- torch\n",
    "- transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593200b2-24ef-46ac-8e30-b908019195f8",
   "metadata": {},
   "source": [
    "## Downloading the Vosk Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a27c6-24e1-4265-965c-aa60e693ca3e",
   "metadata": {},
   "source": [
    "The model can be downloaded using the following link: https://alphacephei.com/vosk/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6065fc40-8275-491c-8079-82f12d66460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12160fa-f15a-4588-af82-471dd617e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_RATE = 16000 # Sampling rate of audio file in Hertz (indication of quality)\n",
    "CHANNELS = 1 # Number of audio channels (speech recognition works best with 1 channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28faeb66-f7af-4124-8fde-9c0e0ae0f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\"vosk-model-small-en-us-0.15\") # 40 MB small model of the English language for ~ 8 GB RAM machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29552db-be94-4cc4-9665-7bdda670561a",
   "metadata": {},
   "source": [
    "## Initialize a Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef183e-d7bc-4f97-839a-53fedd5e966d",
   "metadata": {},
   "source": [
    "Next we are going to initialize a recognizer. We will need the KaldiRecognizer from vosk, which we will load next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f06dcbf-e119-4458-a70a-6363d29b5568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import KaldiRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeeccb0d-f666-4fe4-88a8-9976837d7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = KaldiRecognizer(model, FRAME_RATE)\n",
    "rec.SetWords(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b16c8d-5dd0-46fe-a488-7918e5c0ff60",
   "metadata": {},
   "source": [
    "## Loading an Audio File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d894c-cd75-4946-ada9-dec02eef6b38",
   "metadata": {},
   "source": [
    "Next we will explore how to load an audio file into our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6974b7c-1845-4321-8b05-0f185c18b497",
   "metadata": {},
   "source": [
    "The audio files can be downloaded from this link: https://github.com/dataquestio/project-walkthroughs/tree/master/speech_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8705280-66cc-4e40-8098-e6763361559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a1a42d2-a55b-440f-9a46-fe507daeeca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3 = AudioSegment.from_mp3(\"marketplace.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d0e8a6-7dde-4cf0-aab1-3d4b3c320ac7",
   "metadata": {},
   "source": [
    "We are going to set the channels for this audio file to a single channel only. We will use the single channel variable we specified up top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49bf2d87-b6aa-49ce-8959-60a3bcb6784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3 = mp3.set_channels(CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2398b9bb-3c3d-4aec-9314-b633d130fab9",
   "metadata": {},
   "source": [
    "We are also going to adjust the frame rate to ensure best performance for speech recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa0a7b3-0113-44c4-b955-93372f71eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3 = mp3.set_frame_rate(FRAME_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80f474-8d4c-469a-b484-a14ba4e35517",
   "metadata": {},
   "source": [
    "## Audio File Transcription into Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d686fd-fc7e-4d16-bb39-f6387c7eed0c",
   "metadata": {},
   "source": [
    "We are now going to extract the audio transcription as a text file using our recognizer and vosk model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e13c3183-1131-470d-a35d-84b380d011b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.AcceptWaveform(mp3.raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0736a248-bf7f-4952-9dc4-07ed0b29619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rec.Result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97240e9-e32c-4cfb-9caf-e3260052b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a196768c-154e-4b78-af05-ced12dabc170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the funny thing about the big economic news of the day the fed raising interest rates have a percentage point was that there was only really one bit of actual news in the news and the interest rate increase wasn't it you know it was common i know it was common wall street news common businesses knew it was common so on this fed day on this program something a little bit different j powell in his own words five of i'm his most used economic words from today's press conference where number one of course it's the biggie two percent inflation flesh and inflation inflation inflation place in english dealing with inflation bells big worry that thing keeping him up at night price stability is the feds whole ballgame right now pal basically said as much to day or number two\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = json.loads(result)[\"text\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca360526-5487-4927-8909-b1196e176e83",
   "metadata": {},
   "source": [
    "We used the AcceptWaveform method with the raw data of our mp3 file to obtain the transcription. Getting access to the transcription can be done using the Result method. This result is outputted as a json file, so we need the json library from python to help convert this into a dictionary. The text key has the transcribed text as a value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ead51-051a-478a-99aa-3cfd44fc565e",
   "metadata": {},
   "source": [
    "The first observed issue is that there is no punctuation in this transcript. Also the full result will output the confidence in each word. We could look at the output and decide to replace certain words for which the confidence is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1ff98f7-91f4-440c-aaf8-6375bbcaabe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': [{'conf': 1.0, 'end': 0.15, 'start': 0.0, 'word': 'the'},\n",
       "  {'conf': 1.0, 'end': 0.54, 'start': 0.15, 'word': 'funny'},\n",
       "  {'conf': 1.0, 'end': 0.96, 'start': 0.54, 'word': 'thing'},\n",
       "  {'conf': 1.0, 'end': 1.2, 'start': 0.96, 'word': 'about'},\n",
       "  {'conf': 1.0, 'end': 1.29, 'start': 1.2, 'word': 'the'},\n",
       "  {'conf': 1.0, 'end': 1.68, 'start': 1.29, 'word': 'big'},\n",
       "  {'conf': 1.0, 'end': 2.22, 'start': 1.71, 'word': 'economic'},\n",
       "  {'conf': 1.0, 'end': 2.46, 'start': 2.22, 'word': 'news'},\n",
       "  {'conf': 1.0, 'end': 2.55, 'start': 2.46, 'word': 'of'},\n",
       "  {'conf': 1.0, 'end': 2.64, 'start': 2.55, 'word': 'the'},\n",
       "  {'conf': 1.0, 'end': 3.03, 'start': 2.64, 'word': 'day'},\n",
       "  {'conf': 1.0, 'end': 3.72, 'start': 3.6, 'word': 'the'},\n",
       "  {'conf': 1.0, 'end': 3.96, 'start': 3.72, 'word': 'fed'},\n",
       "  {'conf': 1.0, 'end': 4.26, 'start': 3.96, 'word': 'raising'},\n",
       "  {'conf': 1.0, 'end': 4.59, 'start': 4.26, 'word': 'interest'},\n",
       "  {'conf': 1.0, 'end': 4.98, 'start': 4.59, 'word': 'rates'},\n",
       "  {'conf': 0.695137, 'end': 5.272012, 'start': 5.01, 'word': 'have'},\n",
       "  {'conf': 1.0, 'end': 5.31, 'start': 5.272012, 'word': 'a'},\n",
       "  {'conf': 1.0, 'end': 5.73, 'start': 5.34, 'word': 'percentage'},\n",
       "  {'conf': 1.0, 'end': 6.0, 'start': 5.73, 'word': 'point'},\n",
       "  {'conf': 1.0, 'end': 6.84, 'start': 6.63, 'word': 'was'},\n",
       "  {'conf': 1.0, 'end': 6.96, 'start': 6.84, 'word': 'that'},\n",
       "  {'conf': 1.0, 'end': 7.08, 'start': 6.96, 'word': 'there'},\n",
       "  {'conf': 1.0, 'end': 7.2, 'start': 7.08, 'word': 'was'},\n",
       "  {'conf': 1.0, 'end': 7.47, 'start': 7.2, 'word': 'only'},\n",
       "  {'conf': 1.0, 'end': 7.77, 'start': 7.47, 'word': 'really'},\n",
       "  {'conf': 0.522709, 'end': 8.1, 'start': 7.77, 'word': 'one'},\n",
       "  {'conf': 0.731094, 'end': 8.64, 'start': 8.43, 'word': 'bit'},\n",
       "  {'conf': 1.0, 'end': 8.82, 'start': 8.64, 'word': 'of'},\n",
       "  {'conf': 1.0, 'end': 9.27, 'start': 8.82, 'word': 'actual'},\n",
       "  {'conf': 1.0, 'end': 9.66, 'start': 9.27, 'word': 'news'},\n",
       "  {'conf': 1.0, 'end': 9.78, 'start': 9.66, 'word': 'in'},\n",
       "  {'conf': 1.0, 'end': 9.87, 'start': 9.78, 'word': 'the'},\n",
       "  {'conf': 1.0, 'end': 10.26, 'start': 9.87, 'word': 'news'},\n",
       "  {'conf': 1.0, 'end': 10.47, 'start': 10.26, 'word': 'and'},\n",
       "  {'conf': 1.0, 'end': 10.59, 'start': 10.47, 'word': 'the'},\n",
       "  {'conf': 1.0, 'end': 10.98, 'start': 10.59, 'word': 'interest'},\n",
       "  {'conf': 1.0, 'end': 11.19, 'start': 10.98, 'word': 'rate'},\n",
       "  {'conf': 1.0, 'end': 11.76, 'start': 11.19, 'word': 'increase'},\n",
       "  {'conf': 1.0, 'end': 12.87, 'start': 12.24, 'word': \"wasn't\"},\n",
       "  {'conf': 1.0, 'end': 13.35, 'start': 12.99, 'word': 'it'},\n",
       "  {'conf': 1.0, 'end': 13.62, 'start': 13.38, 'word': 'you'},\n",
       "  {'conf': 1.0, 'end': 13.77, 'start': 13.62, 'word': 'know'},\n",
       "  {'conf': 1.0, 'end': 13.89, 'start': 13.77, 'word': 'it'},\n",
       "  {'conf': 1.0, 'end': 14.01, 'start': 13.89, 'word': 'was'},\n",
       "  {'conf': 1.0, 'end': 14.4, 'start': 14.01, 'word': 'common'},\n",
       "  {'conf': 1.0, 'end': 14.85, 'start': 14.58, 'word': 'i'},\n",
       "  {'conf': 1.0, 'end': 15.03, 'start': 14.85, 'word': 'know'},\n",
       "  {'conf': 1.0, 'end': 15.15, 'start': 15.03, 'word': 'it'},\n",
       "  {'conf': 1.0, 'end': 15.3, 'start': 15.15, 'word': 'was'},\n",
       "  {'conf': 1.0, 'end': 15.63, 'start': 15.3, 'word': 'common'},\n",
       "  {'conf': 0.659231, 'end': 16.11, 'start': 15.63, 'word': 'wall'},\n",
       "  {'conf': 0.659231, 'end': 16.47, 'start': 16.11, 'word': 'street'},\n",
       "  {'conf': 1.0, 'end': 16.86, 'start': 16.47, 'word': 'news'},\n",
       "  {'conf': 0.55188, 'end': 17.19, 'start': 16.86, 'word': 'common'},\n",
       "  {'conf': 1.0, 'end': 18.21, 'start': 17.22, 'word': 'businesses'},\n",
       "  {'conf': 0.82715, 'end': 18.6, 'start': 18.24, 'word': 'knew'},\n",
       "  {'conf': 1.0, 'end': 18.75, 'start': 18.6, 'word': 'it'},\n",
       "  {'conf': 1.0, 'end': 18.93, 'start': 18.75, 'word': 'was'},\n",
       "  {'conf': 0.614166, 'end': 19.29, 'start': 18.93, 'word': 'common'},\n",
       "  {'conf': 1.0, 'end': 20.07, 'start': 19.77, 'word': 'so'},\n",
       "  {'conf': 1.0, 'end': 20.43, 'start': 20.07, 'word': 'on'},\n",
       "  {'conf': 1.0, 'end': 20.76, 'start': 20.52, 'word': 'this'},\n",
       "  {'conf': 1.0, 'end': 21.0, 'start': 20.76, 'word': 'fed'},\n",
       "  {'conf': 1.0, 'end': 21.21, 'start': 21.0, 'word': 'day'},\n",
       "  {'conf': 1.0, 'end': 21.33, 'start': 21.21, 'word': 'on'},\n",
       "  {'conf': 1.0, 'end': 21.48, 'start': 21.33, 'word': 'this'},\n",
       "  {'conf': 1.0, 'end': 21.9, 'start': 21.48, 'word': 'program'},\n",
       "  {'conf': 1.0, 'end': 22.29, 'start': 21.9, 'word': 'something'},\n",
       "  {'conf': 1.0, 'end': 22.35, 'start': 22.29, 'word': 'a'},\n",
       "  {'conf': 1.0, 'end': 22.53, 'start': 22.35, 'word': 'little'},\n",
       "  {'conf': 1.0, 'end': 22.65, 'start': 22.53, 'word': 'bit'},\n",
       "  {'conf': 1.0, 'end': 22.98, 'start': 22.65, 'word': 'different'},\n",
       "  {'conf': 0.553051, 'end': 23.22, 'start': 22.98, 'word': 'j'},\n",
       "  {'conf': 0.923888, 'end': 23.73, 'start': 23.22, 'word': 'powell'},\n",
       "  {'conf': 0.597847, 'end': 23.88, 'start': 23.73, 'word': 'in'},\n",
       "  {'conf': 1.0, 'end': 24.03, 'start': 23.88, 'word': 'his'},\n",
       "  {'conf': 1.0, 'end': 24.3, 'start': 24.03, 'word': 'own'},\n",
       "  {'conf': 1.0, 'end': 24.63, 'start': 24.3, 'word': 'words'},\n",
       "  {'conf': 1.0, 'end': 25.14, 'start': 24.66, 'word': 'five'},\n",
       "  {'conf': 1.0, 'end': 25.26, 'start': 25.14, 'word': 'of'},\n",
       "  {'conf': 0.490052, 'end': 25.41, 'start': 25.26, 'word': \"i'm\"},\n",
       "  {'conf': 1.0, 'end': 25.65, 'start': 25.41, 'word': 'his'},\n",
       "  {'conf': 1.0, 'end': 26.16, 'start': 25.65, 'word': 'most'},\n",
       "  {'conf': 1.0, 'end': 26.64, 'start': 26.19, 'word': 'used'},\n",
       "  {'conf': 1.0, 'end': 27.15, 'start': 26.64, 'word': 'economic'},\n",
       "  {'conf': 0.594545, 'end': 27.36, 'start': 27.15, 'word': 'words'},\n",
       "  {'conf': 1.0, 'end': 27.54, 'start': 27.36, 'word': 'from'},\n",
       "  {'conf': 1.0, 'end': 27.81, 'start': 27.54, 'word': \"today's\"},\n",
       "  {'conf': 1.0, 'end': 28.02, 'start': 27.81, 'word': 'press'},\n",
       "  {'conf': 1.0, 'end': 28.38, 'start': 28.02, 'word': 'conference'},\n",
       "  {'conf': 0.55254, 'end': 29.07, 'start': 28.89, 'word': 'where'},\n",
       "  {'conf': 1.0, 'end': 29.31, 'start': 29.07, 'word': 'number'},\n",
       "  {'conf': 1.0, 'end': 29.55, 'start': 29.31, 'word': 'one'},\n",
       "  {'conf': 1.0, 'end': 29.64, 'start': 29.55, 'word': 'of'},\n",
       "  {'conf': 1.0, 'end': 30.12, 'start': 29.64, 'word': 'course'},\n",
       "  {'conf': 1.0, 'end': 30.36, 'start': 30.15, 'word': \"it's\"},\n",
       "  {'conf': 1.0, 'end': 30.48, 'start': 30.36, 'word': 'the'},\n",
       "  {'conf': 0.453988, 'end': 30.81, 'start': 30.48, 'word': 'biggie'},\n",
       "  {'conf': 0.80125, 'end': 31.44, 'start': 31.2, 'word': 'two'},\n",
       "  {'conf': 1.0, 'end': 31.86, 'start': 31.44, 'word': 'percent'},\n",
       "  {'conf': 1.0, 'end': 32.4, 'start': 31.92, 'word': 'inflation'},\n",
       "  {'conf': 0.490885, 'end': 32.627783, 'start': 32.4, 'word': 'flesh'},\n",
       "  {'conf': 0.426556, 'end': 32.725554, 'start': 32.64, 'word': 'and'},\n",
       "  {'conf': 1.0, 'end': 33.18, 'start': 32.725554, 'word': 'inflation'},\n",
       "  {'conf': 1.0, 'end': 33.81, 'start': 33.18, 'word': 'inflation'},\n",
       "  {'conf': 1.0, 'end': 34.44, 'start': 33.84, 'word': 'inflation'},\n",
       "  {'conf': 1.0, 'end': 34.71, 'start': 34.44, 'word': 'place'},\n",
       "  {'conf': 1.0, 'end': 34.77, 'start': 34.71, 'word': 'in'},\n",
       "  {'conf': 1.0, 'end': 35.1, 'start': 34.77, 'word': 'english'},\n",
       "  {'conf': 1.0, 'end': 35.4, 'start': 35.1, 'word': 'dealing'},\n",
       "  {'conf': 1.0, 'end': 35.55, 'start': 35.4, 'word': 'with'},\n",
       "  {'conf': 1.0, 'end': 36.03, 'start': 35.55, 'word': 'inflation'},\n",
       "  {'conf': 0.789621, 'end': 36.63, 'start': 36.3, 'word': 'bells'},\n",
       "  {'conf': 1.0, 'end': 36.87, 'start': 36.63, 'word': 'big'},\n",
       "  {'conf': 1.0, 'end': 37.17, 'start': 36.87, 'word': 'worry'},\n",
       "  {'conf': 0.558685, 'end': 37.285745, 'start': 37.17, 'word': 'that'},\n",
       "  {'conf': 1.0, 'end': 37.53, 'start': 37.285745, 'word': 'thing'},\n",
       "  {'conf': 1.0, 'end': 37.921542, 'start': 37.53, 'word': 'keeping'},\n",
       "  {'conf': 0.813008, 'end': 38.07, 'start': 37.921542, 'word': 'him'},\n",
       "  {'conf': 1.0, 'end': 38.25, 'start': 38.07, 'word': 'up'},\n",
       "  {'conf': 1.0, 'end': 38.34, 'start': 38.25, 'word': 'at'},\n",
       "  {'conf': 1.0, 'end': 38.67, 'start': 38.37, 'word': 'night'},\n",
       "  {'conf': 1.0, 'end': 39.24, 'start': 38.7, 'word': 'price'},\n",
       "  {'conf': 1.0, 'end': 40.38, 'start': 39.3, 'word': 'stability'},\n",
       "  {'conf': 1.0, 'end': 40.65, 'start': 40.41, 'word': 'is'},\n",
       "  {'conf': 1.0, 'end': 40.77, 'start': 40.65, 'word': 'the'},\n",
       "  {'conf': 0.419379, 'end': 41.13, 'start': 40.77, 'word': 'feds'},\n",
       "  {'conf': 1.0, 'end': 41.64, 'start': 41.171202, 'word': 'whole'},\n",
       "  {'conf': 0.717333, 'end': 42.3, 'start': 41.64, 'word': 'ballgame'},\n",
       "  {'conf': 1.0, 'end': 42.48, 'start': 42.3, 'word': 'right'},\n",
       "  {'conf': 1.0, 'end': 42.75, 'start': 42.48, 'word': 'now'},\n",
       "  {'conf': 0.26863, 'end': 43.14, 'start': 42.78, 'word': 'pal'},\n",
       "  {'conf': 1.0, 'end': 43.62, 'start': 43.146138, 'word': 'basically'},\n",
       "  {'conf': 1.0, 'end': 44.01, 'start': 43.62, 'word': 'said'},\n",
       "  {'conf': 1.0, 'end': 44.25, 'start': 44.01, 'word': 'as'},\n",
       "  {'conf': 1.0, 'end': 44.61, 'start': 44.25, 'word': 'much'},\n",
       "  {'conf': 0.62198, 'end': 44.91, 'start': 44.76, 'word': 'to'},\n",
       "  {'conf': 0.62198, 'end': 45.15, 'start': 44.91, 'word': 'day'},\n",
       "  {'conf': 1.0, 'end': 45.3, 'start': 45.15, 'word': 'or'},\n",
       "  {'conf': 1.0, 'end': 45.51, 'start': 45.3, 'word': 'number'},\n",
       "  {'conf': 1.0, 'end': 45.84, 'start': 45.51, 'word': 'two'}],\n",
       " 'text': \"the funny thing about the big economic news of the day the fed raising interest rates have a percentage point was that there was only really one bit of actual news in the news and the interest rate increase wasn't it you know it was common i know it was common wall street news common businesses knew it was common so on this fed day on this program something a little bit different j powell in his own words five of i'm his most used economic words from today's press conference where number one of course it's the biggie two percent inflation flesh and inflation inflation inflation place in english dealing with inflation bells big worry that thing keeping him up at night price stability is the feds whole ballgame right now pal basically said as much to day or number two\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890d279-2011-46c4-9bf7-afa2cecb6a95",
   "metadata": {},
   "source": [
    "## Adding Punctuation to the Transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19c28ac-365c-4b94-936c-5af22e797f36",
   "metadata": {},
   "source": [
    "As mentioned, punctuation is missing from the official output. We can add punctuation using the recasepunc library. Luckily for us, vosk has trained its models to already make use of recasepunc. Unfortunately, these models are at least 1 GB large. This project therefore needs to be done on a machine with at least 16 GB of RAM. We will skip this step since we currently only have access to 8 GB of RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba892f-4978-468f-8425-9ae7a3f54a28",
   "metadata": {},
   "source": [
    "## Transcribing Longer Audio Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fca49a-3641-4314-b104-564b963f1013",
   "metadata": {},
   "source": [
    "We are now going to build a custom function that will split longer audio files in 45 second bits. Vosk does not work well with longer audio files since it will consume too much memory and inference becomes slow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a23dbf0-5cea-43da-85ef-5c43eb7d335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcriber(file: str) -> str: \n",
    "    # Initializing a recognizer using the Vosk model and frame_rate\n",
    "    rec = KaldiRecognizer(model, FRAME_RATE)\n",
    "    rec.SetWords(True)\n",
    "\n",
    "    # Loading an audio file\n",
    "    mp3 = AudioSegment.from_mp3(f\"{file}.mp3\")\n",
    "    mp3 = mp3.set_channels(CHANNELS)\n",
    "    mp3 = mp3.set_frame_rate(FRAME_RATE)\n",
    "\n",
    "    step = 45000\n",
    "    transcript = \"\"\n",
    "    for i in range(0, len(mp3), step):\n",
    "\n",
    "        print(f\"Progress: {round(i / len(mp3) * 100)}%\")\n",
    "        \n",
    "        segment = mp3[i:(i+step)]\n",
    "        rec.AcceptWaveform(segment.raw_data)\n",
    "        result = rec.Result()\n",
    "        text_segment = json.loads(result)[\"text\"]\n",
    "\n",
    "        transcript += text_segment\n",
    "\n",
    "    return transcript\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1b83df7-0778-4bb5-9968-c765b7e4e418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0%\n",
      "Progress: 98%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"the funny thing about the big economic news of the day the fed raising interest rates have a percentage point was that there was only really one bit of actual news in the news and the interest rate increase wasn't it you know it was common i know it was common wall street news common businesses knew it was common so on this fed day on this program something a little bit different j powell in his own words five of i'm his most used economic words from today's press conference where number one of course it's the biggie two percent inflation flesh and inflation inflation inflation place in english dealing with inflation bells big worry that thing keeping him up at night price stability is the feds whole ballgame right now pal basically said as muchtoday or number two\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber(\"marketplace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea096a-1333-4a1a-a0c5-7f895cfdada5",
   "metadata": {},
   "source": [
    "Running the function on the previous 45 second slice returns a similar transcript output as before and so we know that our function works well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e51ec6-cf5d-4e3b-a8bb-3866132c3d40",
   "metadata": {},
   "source": [
    "## Summarizing the Transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae0b97-0bc0-4132-a90f-39b84d8cbd76",
   "metadata": {},
   "source": [
    "Next we will look at the summarization of the transcripts using the HuggingFace pretrained transformer library. We initially imported transformers, which we will make use of now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64ffe697-18f2-45dc-8a01-789aa6b98d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6ba200d-77a8-46a3-86bd-9461f01280c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1b0731c-e9f3-467b-896c-3937e2ca6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text = text.split() # split the transcribed text on spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d5878b7-0f72-4772-ac4c-1714eba5f411",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for i in range(0, len(split_text), 850):\n",
    "    selection = \" \".join(split_text[i:(i+850)])\n",
    "    docs.append(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32e88ab8-4a6a-4957-8388-83a8d1b8fb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"the funny thing about the big economic news of the day the fed raising interest rates have a percentage point was that there was only really one bit of actual news in the news and the interest rate increase wasn't it you know it was common i know it was common wall street news common businesses knew it was common so on this fed day on this program something a little bit different j powell in his own words five of i'm his most used economic words from today's press conference where number one of course it's the biggie two percent inflation flesh and inflation inflation inflation place in english dealing with inflation bells big worry that thing keeping him up at night price stability is the feds whole ballgame right now pal basically said as much to day or number two\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c26a39-4ae1-492e-9663-e148b0f8e855",
   "metadata": {},
   "source": [
    "We just split the small transcribed text and joined it together in a list. This method works better for larger texts which we will play around with after the small transcribed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62c9a748-14ba-48ae-afa9-0806a24d7808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but your input_length is only 163. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=81)\n"
     ]
    }
   ],
   "source": [
    "summaries = summarizer(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f4e8e7d-3250-458f-8d5f-cb6704feceaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the biggie two percent inflation flesh and inflation inflation inflation place in english dealing with inflation bells big worry that thing keeping him up at night price stability is the feds whole ballgame right now pal basically said as much to day or number two .'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe938635-af62-458d-9b06-57f9b55351af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the biggie two percent inflation flesh and inflation inflation inflation place in english dealing with inflation bells big worry that thing keeping him up at night price stability is the feds whole ballgame right now pal basically said as much to day or number two .'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = \"\\n\\n\".join(d[\"summary_text\"] for d in summaries)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ababce5-259f-445a-a6b1-071d625fa7e8",
   "metadata": {},
   "source": [
    "We just used the huggingface summarizer tool to produce a summary of the small podcast. Next we will build a custom function to do this work automatically for us and then connect both custom functions together to build a pipeline of podcast to summary conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94268d43-04a7-4077-983d-68ff92180ff1",
   "metadata": {},
   "source": [
    "## Building Custom Summarizer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54fa58b7-56f2-43d3-87d1-e1e258493969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizer(transcript: str) -> str:\n",
    "    split_transcript = transcript.split()\n",
    "\n",
    "    docs = []\n",
    "    step = 850\n",
    "    for i in range(0, len(split_transcript), step):\n",
    "        selection = \" \".join(split_transcript[i:(i+step)])\n",
    "        docs.append(selection)\n",
    "\n",
    "    summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
    "    summaries = summarizer(docs)\n",
    "\n",
    "    summary = \" \".join(d[\"summary_text\"] for d in summaries)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e620d72-9370-4c8c-b382-ac40adeb14cb",
   "metadata": {},
   "source": [
    "The above custom function should return a summary using the huggingface pretrained transformer. The function takes a transcript as input. We will now chain both functions together (transcriber and summarizer) to provide a single function to automatically return a summary from a transcribed podcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c36f1d0-f2c0-49e9-8171-68f9a4e3c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcriber_summarizer(file):\n",
    "\n",
    "    return summarizer(transcriber(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a647b6-4032-4b9b-acef-a80563ebb2b8",
   "metadata": {},
   "source": [
    "Next we are going to test this function on the full marketplace podcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47578f9c-cdcd-46cf-8e9a-bdc5cd42ba63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0%\n",
      "Progress: 3%\n",
      "Progress: 5%\n",
      "Progress: 8%\n",
      "Progress: 11%\n",
      "Progress: 13%\n",
      "Progress: 16%\n",
      "Progress: 19%\n",
      "Progress: 21%\n",
      "Progress: 24%\n",
      "Progress: 27%\n",
      "Progress: 29%\n",
      "Progress: 32%\n",
      "Progress: 35%\n",
      "Progress: 37%\n",
      "Progress: 40%\n",
      "Progress: 43%\n",
      "Progress: 45%\n",
      "Progress: 48%\n",
      "Progress: 51%\n",
      "Progress: 53%\n",
      "Progress: 56%\n",
      "Progress: 59%\n",
      "Progress: 61%\n",
      "Progress: 64%\n",
      "Progress: 67%\n",
      "Progress: 69%\n",
      "Progress: 72%\n",
      "Progress: 75%\n",
      "Progress: 77%\n",
      "Progress: 80%\n",
      "Progress: 83%\n",
      "Progress: 85%\n",
      "Progress: 88%\n",
      "Progress: 91%\n",
      "Progress: 93%\n",
      "Progress: 96%\n",
      "Progress: 99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"elon musk has sealed the deal as of today lauren hirsch has been covering the story for the new york times thanks for having me set aside all marijuana jokes that many people paid with this price clearly he was serious . in i i think both people never that a deal would have happened and even if people thought they weren't a bea deal i don't think anyone thought it could happen deskquickly he gets all the money together they have these board meetings over i think we all need to rethink their ramifications on communication in a country lord hirsch covers business and most recently the twitter story new almost for the new york times or thanks for having me that introduction by the way tootwo hundred and forty five characters nailed it it's twitter shares on this monday up almost six percent still though a couple about shy of must offer of fifty four dollars twenty cents bees elsewhere major indices were up . the national association for business economics is out the new survey of economists to work at big companies . i'm nancy marshall cancer for marketplace german up you need to keep that stock up or someone will do it for you moron even first . check out dot com is a leading digital payment solutions provider for brands like grab sony electronics wise and henkel checkouts flexible payments platform . i owe slash marketplace to skip the wait list that's masterwork start . this marketplace podcast is supported by a dedicated team of local experts spanning nineteen offices and five continents . it's a strategic partnership to help businesses improve their acceptance rates optimize their payments performance . the drucker institute says what began to erode at this time is what he calls the corporate social contract that basically said if you come to work every day and you give the corporation a measure ofloyalty we in turn will take care of you often for the rest of your life . i'd put it right up there with any of those other factors to many the relevant case study here is general electric in the nineteen eighties run by an old college hockey captain named jack welch . fashion in one study of the snp five hundred companies the sheriff profits going to stockholders has gone from fifty percent in the early eighties to eighty six percent in twenty third team leaving in ever shrinking pool of money to invest in the businesses themselves . warren buffett auctioned off a steak lunch with him every year proceeds to charity and san francisco hasn't happened obviously since two thousand and nineteen and this year's launch we are told will be the last buffet is after all nine\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriber_summarizer(\"marketplace_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2422b-eeac-4cd4-a26c-4055aeff8a64",
   "metadata": {},
   "source": [
    "We have now obtained a summary attempt of a lengthy podcast. We can clearly tell than punctuation is missing, which would make the summary more legible. Using the larger vosk models and summarizer models would also improve the quality of the output. Other modifications that could be made to potentially improve the quality is the steps and the splitting of the tokens, although that will make the processing slower."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
